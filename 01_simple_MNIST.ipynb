{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 01: Writing first MNIST Program\n",
    "By Rahul GAWAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This program is inspired by [GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials)\n",
    "\n",
    "Python used: 3.6\n",
    "TensorFlow version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_w = 28\n",
    "img_h = 28\n",
    "img_shape = (img_w, img_h)\n",
    "img_shape_storage = (img_w, img_h, 1)\n",
    "\n",
    "url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "\n",
    "x_train_file = \"train-images-idx3-ubyte.gz\"\n",
    "y_train_file = \"train-labels-idx1-ubyte.gz\"\n",
    "x_test_file = \"t10k-images-idx3-ubyte.gz\"\n",
    "y_test_file = \"t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "target = \"mnist_dataset\"\n",
    "\n",
    "x_train_url = url + x_train_file\n",
    "y_train_url = url + y_train_file\n",
    "x_test_url = url + x_test_file\n",
    "y_test_url = url + y_test_file\n",
    "\n",
    "x_train_rpath = target + \"/\" + x_train_file\n",
    "y_train_rpath = target + \"/\" + y_train_file\n",
    "x_test_rpath = target + \"/\" + x_test_file\n",
    "y_test_rpath = target + \"/\" + y_test_file\n",
    "\n",
    "training_recname = '%s/mnist_%s.tfrecord' % (target, x_train_file)\n",
    "testing_recname = '%s/mnist_%s.tfrecord' % (target, x_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset to a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_download_progress(count, block_size, total_size):\n",
    "    \"\"\"\n",
    "    Function used for printing the download progress.\n",
    "    Used as a call-back function in maybe_download_and_extract().\n",
    "    \"\"\"\n",
    "\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count * block_size) / total_size\n",
    "\n",
    "    # Limit it because rounding errors may cause it to exceed 100%.\n",
    "    pct_complete = min(1.0, pct_complete)\n",
    "\n",
    "    # Status-message. Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Download progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_img(base_url, filename, download_dir, offset):\n",
    "\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "\n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"\\nDownloading\", base_url, \"at\", download_dir, \".\")\n",
    "        file_path, _ = urllib.request.urlretrieve( base_url, file_path, _print_download_progress)\n",
    "\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=offset)\n",
    "\n",
    "    img_size = 28\n",
    "    img_size_flat = img_size * img_size\n",
    "    num_channels = 1\n",
    "    img_shape_full = (img_size, img_size, num_channels)\n",
    "    images_flat = data.reshape(-1, img_size_flat)\n",
    "    return images_flat\n",
    "\n",
    "def download_cls(base_url, filename, download_dir,  offset):\n",
    "\n",
    "    if not os.path.exists(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "\n",
    "    file_path = os.path.join(download_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"\\nDownloading\", base_url, \"at\", download_dir, \".\")\n",
    "        file_path, _ = urllib.request.urlretrieve( base_url, file_path, _print_download_progress)\n",
    "\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8,  offset=offset)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train Set 60000\n",
      "y_train_cls Set 60000\n",
      "\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz at mnist_dataset .\n",
      "- Download progress: 100.0%x_test Set 10000\n",
      "\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz at mnist_dataset .\n",
      "- Download progress: 100.0%y_test_cls Set 10000\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "#save_path = os.path.join(download_dir, filename)\n",
    "\n",
    "x_train = download_img(x_train_url, x_train_file, target,16)\n",
    "print(\"x_train Set\", len(x_train))\n",
    "\n",
    "y_train_cls = download_cls(y_train_url, y_train_file, target,8)\n",
    "print(\"y_train_cls Set\", len(y_train_cls))\n",
    "\n",
    "x_test = download_img(x_test_url, x_test_file, target,16)\n",
    "print(\"x_test Set\", len(x_test))\n",
    "\n",
    "y_test_cls = download_cls(y_test_url, y_test_file, target,8)\n",
    "print(\"y_test_cls Set\", len(y_test_cls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set 55000  images and  55000  classes.\n",
      "Validation Set 5000  images and  5000  classes.\n",
      "Test Set 10000  images and  10000  classes.\n"
     ]
    }
   ],
   "source": [
    "num_train = 55000\n",
    "num_val = 5000\n",
    "num_test = 10000\n",
    "\n",
    "X_train = x_train[0:num_train] / 255.0\n",
    "Y_train_cls = y_train_cls[0:num_train]\n",
    "\n",
    "X_val = x_train[num_train:] / 255.0\n",
    "Y_val_cls = y_train_cls[num_train:]\n",
    "\n",
    "print(\"Training Set\", len(X_train), \" images and \", len(Y_train_cls), \" classes.\")\n",
    "print(\"Validation Set\", len(X_val), \" images and \", len(Y_val_cls), \" classes.\")\n",
    "\n",
    "X_test = x_train[0:num_test] / 255.0\n",
    "Y_test_cls = y_test_cls[0:num_test]\n",
    "\n",
    "print(\"Test Set\", len(X_test), \" images and \", len(Y_test_cls), \" classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None, img_w=28, img_h=28):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "\n",
    "\n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = X_test[0:9]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = Y_test_cls[0:9]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cls_char = Y_train_cls.astype(np.int)\n",
    "y_val_cls_char = Y_val_cls.astype(np.int)\n",
    "y_test_cls_char = Y_test_cls.astype(np.int)\n",
    "\n",
    "Y_train_OHE = np.eye(10, dtype=float)[y_train_cls_char]\n",
    "Y_val_OHE = np.eye(10, dtype=float)[y_val_cls_char]\n",
    "Y_test_OHE = np.eye(10, dtype=float)[y_test_cls_char]\n",
    "\n",
    "Y_test_OHE[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-record (Optional)\n",
    "\n",
    "[Referred this implementation to create tf.record](https://github.com/tensorflow/models/blob/master/research/slim/datasets/download_and_convert_mnist.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int64_feature(values):\n",
    "  if not isinstance(values, (tuple, list)):\n",
    "    values = [values]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tfexample(image_data, image_format, height, width, class_id):\n",
    "  return tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/encoded':  tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_data])),\n",
    "      'image/format':  tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n",
    "      'image/class/label': int64_feature(class_id),\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width)\n",
    "  }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _add_to_tfrecord(data_filename, labels_filename, num_images, tfrecord_writer, images, labels):\n",
    "    with tf.Graph().as_default():\n",
    "        image = tf.placeholder(dtype=tf.uint8, shape=img_shape_storage)\n",
    "        encoded_png = tf.image.encode_png(image)\n",
    "\n",
    "        num_images = len(images)\n",
    "        images = images.reshape(-1, img_w, img_h, 1)\n",
    "\n",
    "        with tf.Session('') as sess:\n",
    "            for j in range(num_images):\n",
    "                sys.stdout.write('\\r>> Converting image %d/%d' % (j + 1, num_images))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                png_string = sess.run(encoded_png, feed_dict={image: images[j]})\n",
    "                example = image_to_tfexample(png_string, 'png'.encode(), img_w, img_h, labels[j])\n",
    "                tfrecord_writer.write(example.SerializeToString())\n",
    "\n",
    "#                pngFname = target + \"/\" + \"train_%d.png\" % (j)\n",
    "#                pngFile=open(pngFname,'wb')\n",
    "#                pngFile.write(png_string);\n",
    "#                pngFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Set 60000\n",
      "y_train_cls Set 60000\n",
      "x_test Set 10000\n",
      "y_test_cls Set 10000\n",
      "60000\n",
      ">> Converting image 3000/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 8484/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 13971/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 19514/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 24886/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 30433/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 35607/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 41142/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 46600/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 52153/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 57722/60000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 3228/10000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 8360/10000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = download_img(x_train_url, x_train_file, target,16)\n",
    "print(\"x_train Set\", len(x_train))\n",
    "\n",
    "y_train_cls = download_cls(y_train_url, y_train_file, target,8)\n",
    "print(\"y_train_cls Set\", len(y_train_cls))\n",
    "\n",
    "x_test = download_img(x_test_url, x_test_file, target,16)\n",
    "print(\"x_test Set\", len(x_test))\n",
    "\n",
    "y_test_cls = download_cls(y_test_url, y_test_file, target,8)\n",
    "print(\"y_test_cls Set\", len(y_test_cls))\n",
    "\n",
    "print(len(x_train))\n",
    "\n",
    "if not os.path.exists(training_recname):\n",
    "    with tf.python_io.TFRecordWriter(training_recname) as tfrecord_writer:\n",
    "        _add_to_tfrecord(x_train_rpath, y_train_rpath, 60000, tfrecord_writer, x_train, y_train_cls)\n",
    "\n",
    "if not os.path.exists(testing_recname):\n",
    "    with tf.python_io.TFRecordWriter(testing_recname) as tfrecord_writer:\n",
    "        _add_to_tfrecord(x_test_rpath, y_test_rpath, 10000, tfrecord_writer, x_test, y_test_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    keys_to_features = {\n",
    "        \"image/encoded\":  tf.FixedLenFeature([], tf.string),\n",
    "        \"image/format\":  tf.FixedLenFeature([], tf.string),\n",
    "        \"image/class/label\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/width\": tf.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "    height = tf.cast(parsed[\"image/height\"], tf.int32)\n",
    "    width = tf.cast(parsed[\"image/width\"], tf.int32)\n",
    "    label = tf.cast(parsed[\"image/class/label\"], tf.int32)\n",
    "    image = tf.cast(tf.image.decode_png(parsed[\"image/encoded\"], channels=1), tf.float32)\n",
    "    \n",
    " \n",
    "    return {'image': image}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filenames):\n",
    "    \n",
    "    BATCH_SIZE = 128\n",
    "    THREADS = 4\n",
    "    PREFETCH = 64\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames=filenames, num_parallel_reads=THREADS)\n",
    "    dataset = dataset.apply(\n",
    "        tf.contrib.data.shuffle_and_repeat(1024, 1)\n",
    "    )\n",
    "    dataset = dataset.apply(\n",
    "        tf.contrib.data.map_and_batch(parser, BATCH_SIZE)\n",
    "    )\n",
    "\n",
    "    dataset = dataset.prefetch(buffer_size=PREFETCH)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filenames=[training_recname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_input_fn():\n",
    "    return input_fn(filenames=[testing_recname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "\n",
    "    net = features[\"image\"]\n",
    "\n",
    "    net = tf.identity(net, name=\"input_tensor\")\n",
    "\n",
    "    net = tf.reshape(net, [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(inputs=net, filters=32,kernel_size=[5, 5],padding=\"same\", activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1,filters=64,kernel_size=[5, 5],padding=\"same\",activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1), \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9b5c990710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 44.256187, step = 0\n",
      "INFO:tensorflow:global_step/sec: 262.211\n",
      "INFO:tensorflow:loss = 0.649611, step = 100 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.257\n",
      "INFO:tensorflow:loss = 0.46949852, step = 200 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.593\n",
      "INFO:tensorflow:loss = 0.28218517, step = 300 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.777\n",
      "INFO:tensorflow:loss = 0.16210127, step = 400 (0.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 469 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.13093846.\n",
      "Time Take per Iternation of training is : 197.093231%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-469\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:07\n",
      "INFO:tensorflow:Saving dict for global step 469: accuracy = 0.9551, global_step = 469, loss = 0.1446513\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 469: model5/model.ckpt-469\n",
      "Classification accuracy: 95.51%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-469\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 469 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.32387033, step = 469\n",
      "INFO:tensorflow:global_step/sec: 288.841\n",
      "INFO:tensorflow:loss = 0.22932069, step = 569 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.65\n",
      "INFO:tensorflow:loss = 0.42520738, step = 669 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.542\n",
      "INFO:tensorflow:loss = 0.11990617, step = 769 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.426\n",
      "INFO:tensorflow:loss = 0.081516184, step = 869 (0.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 938 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.26692536.\n",
      "Time Take per Iternation of training is : 183.342846%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-938\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:09\n",
      "INFO:tensorflow:Saving dict for global step 938: accuracy = 0.9672, global_step = 938, loss = 0.099926546\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 938: model5/model.ckpt-938\n",
      "Classification accuracy: 96.72%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-938\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 938 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.18896449, step = 938\n",
      "INFO:tensorflow:global_step/sec: 287.574\n",
      "INFO:tensorflow:loss = 0.10565077, step = 1038 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.719\n",
      "INFO:tensorflow:loss = 0.15832423, step = 1138 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.049\n",
      "INFO:tensorflow:loss = 0.09133952, step = 1238 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.457\n",
      "INFO:tensorflow:loss = 0.1812551, step = 1338 (0.333 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1407 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.31191394.\n",
      "Time Take per Iternation of training is : 190.320822%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-1407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:11\n",
      "INFO:tensorflow:Saving dict for global step 1407: accuracy = 0.974, global_step = 1407, loss = 0.08104245\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1407: model5/model.ckpt-1407\n",
      "Classification accuracy: 97.40%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-1407\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1407 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.18094547, step = 1407\n",
      "INFO:tensorflow:global_step/sec: 263.232\n",
      "INFO:tensorflow:loss = 0.10645704, step = 1507 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.129\n",
      "INFO:tensorflow:loss = 0.18302509, step = 1607 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.582\n",
      "INFO:tensorflow:loss = 0.13883136, step = 1707 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.136\n",
      "INFO:tensorflow:loss = 0.09239061, step = 1807 (0.325 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1876 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.055805758.\n",
      "Time Take per Iternation of training is : 215.768421%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-1876\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:14\n",
      "INFO:tensorflow:Saving dict for global step 1876: accuracy = 0.9771, global_step = 1876, loss = 0.07065242\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1876: model5/model.ckpt-1876\n",
      "Classification accuracy: 97.71%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-1876\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1876 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.108176224, step = 1876\n",
      "INFO:tensorflow:global_step/sec: 293.301\n",
      "INFO:tensorflow:loss = 0.16310646, step = 1976 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.361\n",
      "INFO:tensorflow:loss = 0.0769421, step = 2076 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.078\n",
      "INFO:tensorflow:loss = 0.07928127, step = 2176 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.229\n",
      "INFO:tensorflow:loss = 0.052571535, step = 2276 (0.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2345 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.043640982.\n",
      "Time Take per Iternation of training is : 186.805347%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-2345\n",
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:16\n",
      "INFO:tensorflow:Saving dict for global step 2345: accuracy = 0.9781, global_step = 2345, loss = 0.06419275\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2345: model5/model.ckpt-2345\n",
      "Classification accuracy: 97.81%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-2345\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2345 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.062330887, step = 2345\n",
      "INFO:tensorflow:global_step/sec: 294.213\n",
      "INFO:tensorflow:loss = 0.061678126, step = 2445 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.408\n",
      "INFO:tensorflow:loss = 0.10496263, step = 2545 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.715\n",
      "INFO:tensorflow:loss = 0.116833664, step = 2645 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.108\n",
      "INFO:tensorflow:loss = 0.11210143, step = 2745 (0.294 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2814 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.115709625.\n",
      "Time Take per Iternation of training is : 183.020818%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-2814\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:18\n",
      "INFO:tensorflow:Saving dict for global step 2814: accuracy = 0.9807, global_step = 2814, loss = 0.05869302\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2814: model5/model.ckpt-2814\n",
      "Classification accuracy: 98.07%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-2814\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2814 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.09950299, step = 2814\n",
      "INFO:tensorflow:global_step/sec: 295.997\n",
      "INFO:tensorflow:loss = 0.087226816, step = 2914 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.596\n",
      "INFO:tensorflow:loss = 0.06578501, step = 3014 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.842\n",
      "INFO:tensorflow:loss = 0.049062867, step = 3114 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.355\n",
      "INFO:tensorflow:loss = 0.19196576, step = 3214 (0.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3283 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.106622964.\n",
      "Time Take per Iternation of training is : 189.898266%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-3283\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:21\n",
      "INFO:tensorflow:Saving dict for global step 3283: accuracy = 0.982, global_step = 3283, loss = 0.05629437\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3283: model5/model.ckpt-3283\n",
      "Classification accuracy: 98.20%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-3283\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3283 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.046328526, step = 3283\n",
      "INFO:tensorflow:global_step/sec: 291.31\n",
      "INFO:tensorflow:loss = 0.13243397, step = 3383 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.78\n",
      "INFO:tensorflow:loss = 0.12411053, step = 3483 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.852\n",
      "INFO:tensorflow:loss = 0.096395075, step = 3583 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.834\n",
      "INFO:tensorflow:loss = 0.04892034, step = 3683 (0.287 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3752 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2443198.\n",
      "Time Take per Iternation of training is : 184.056265%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:23\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-3752\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:23\n",
      "INFO:tensorflow:Saving dict for global step 3752: accuracy = 0.9818, global_step = 3752, loss = 0.05229732\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3752: model5/model.ckpt-3752\n",
      "Classification accuracy: 98.18%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-3752\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3752 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.030086577, step = 3752\n",
      "INFO:tensorflow:global_step/sec: 296.331\n",
      "INFO:tensorflow:loss = 0.035775736, step = 3852 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.178\n",
      "INFO:tensorflow:loss = 0.12299639, step = 3952 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.921\n",
      "INFO:tensorflow:loss = 0.106650256, step = 4052 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.204\n",
      "INFO:tensorflow:loss = 0.056349963, step = 4152 (0.289 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4221 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.028704604.\n",
      "Time Take per Iternation of training is : 183.256018%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-4221\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:25\n",
      "INFO:tensorflow:Saving dict for global step 4221: accuracy = 0.983, global_step = 4221, loss = 0.04722427\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4221: model5/model.ckpt-4221\n",
      "Classification accuracy: 98.30%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-4221\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4221 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.1070254, step = 4221\n",
      "INFO:tensorflow:global_step/sec: 295.208\n",
      "INFO:tensorflow:loss = 0.07172343, step = 4321 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.196\n",
      "INFO:tensorflow:loss = 0.01881666, step = 4421 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.258\n",
      "INFO:tensorflow:loss = 0.0757077, step = 4521 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.99\n",
      "INFO:tensorflow:loss = 0.17405373, step = 4621 (0.290 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4690 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07898935.\n",
      "Time Take per Iternation of training is : 191.766500%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-4690\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:27\n",
      "INFO:tensorflow:Saving dict for global step 4690: accuracy = 0.9839, global_step = 4690, loss = 0.044483818\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4690: model5/model.ckpt-4690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 98.39%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-4690\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4690 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.1115748, step = 4690\n",
      "INFO:tensorflow:global_step/sec: 296.283\n",
      "INFO:tensorflow:loss = 0.09416169, step = 4790 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.815\n",
      "INFO:tensorflow:loss = 0.10453527, step = 4890 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.47\n",
      "INFO:tensorflow:loss = 0.16326746, step = 4990 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.968\n",
      "INFO:tensorflow:loss = 0.12645699, step = 5090 (0.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5159 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0115626305.\n",
      "Time Take per Iternation of training is : 185.524431%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-5159\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:30\n",
      "INFO:tensorflow:Saving dict for global step 5159: accuracy = 0.984, global_step = 5159, loss = 0.044334125\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5159: model5/model.ckpt-5159\n",
      "Classification accuracy: 98.40%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-5159\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5159 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.08104651, step = 5159\n",
      "INFO:tensorflow:global_step/sec: 292.534\n",
      "INFO:tensorflow:loss = 0.07203303, step = 5259 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.214\n",
      "INFO:tensorflow:loss = 0.03334015, step = 5359 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.87\n",
      "INFO:tensorflow:loss = 0.035389222, step = 5459 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.758\n",
      "INFO:tensorflow:loss = 0.07255046, step = 5559 (0.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5628 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.08183318.\n",
      "Time Take per Iternation of training is : 184.874229%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-5628\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:32\n",
      "INFO:tensorflow:Saving dict for global step 5628: accuracy = 0.9847, global_step = 5628, loss = 0.04248218\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5628: model5/model.ckpt-5628\n",
      "Classification accuracy: 98.47%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-5628\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5628 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.102945514, step = 5628\n",
      "INFO:tensorflow:global_step/sec: 291.79\n",
      "INFO:tensorflow:loss = 0.10993743, step = 5728 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.557\n",
      "INFO:tensorflow:loss = 0.03686328, step = 5828 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.086\n",
      "INFO:tensorflow:loss = 0.030844383, step = 5928 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.414\n",
      "INFO:tensorflow:loss = 0.02706618, step = 6028 (0.289 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6097 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.10309875.\n",
      "Time Take per Iternation of training is : 193.301893%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-6097\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:34\n",
      "INFO:tensorflow:Saving dict for global step 6097: accuracy = 0.9843, global_step = 6097, loss = 0.04201428\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6097: model5/model.ckpt-6097\n",
      "Classification accuracy: 98.43%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-6097\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 6097 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.08849647, step = 6097\n",
      "INFO:tensorflow:global_step/sec: 297.799\n",
      "INFO:tensorflow:loss = 0.07718791, step = 6197 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.567\n",
      "INFO:tensorflow:loss = 0.060875233, step = 6297 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.41\n",
      "INFO:tensorflow:loss = 0.12870146, step = 6397 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.917\n",
      "INFO:tensorflow:loss = 0.04935944, step = 6497 (0.286 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6566 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.08374516.\n",
      "Time Take per Iternation of training is : 181.987585%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:36\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-6566\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:36\n",
      "INFO:tensorflow:Saving dict for global step 6566: accuracy = 0.986, global_step = 6566, loss = 0.038772166\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6566: model5/model.ckpt-6566\n",
      "Classification accuracy: 98.60%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-6566\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 6566 into model5/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.06722608, step = 6566\n",
      "INFO:tensorflow:global_step/sec: 295.413\n",
      "INFO:tensorflow:loss = 0.024136769, step = 6666 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.046\n",
      "INFO:tensorflow:loss = 0.022167796, step = 6766 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.815\n",
      "INFO:tensorflow:loss = 0.043744728, step = 6866 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.27\n",
      "INFO:tensorflow:loss = 0.04728365, step = 6966 (0.288 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7035 into model5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0032100503.\n",
      "Time Take per Iternation of training is : 183.214512%INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-07-16:23:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-7035\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-07-16:23:39\n",
      "INFO:tensorflow:Saving dict for global step 7035: accuracy = 0.9848, global_step = 7035, loss = 0.039628454\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7035: model5/model.ckpt-7035\n",
      "Classification accuracy: 98.48%"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "model = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
    "                               params={\"learning_rate\": 1e-4},\n",
    "                               model_dir=\"model5\")\n",
    "\n",
    "import timeit\n",
    "\n",
    "EPOCHS = 15\n",
    "STEP_SIZE = 500\n",
    "count = 0\n",
    "\n",
    "while (count < EPOCHS):\n",
    "    start_time = timeit.default_timer()\n",
    "    model.train(input_fn=train_input_fn, steps=STEP_SIZE)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    sys.stdout.write(\"Time Take per Iternation of training is : {0:%}\".format(elapsed))\n",
    "\n",
    "    result = model.evaluate(input_fn=val_input_fn)\n",
    "    #print(result)\n",
    "    sys.stdout.write(\"Classification accuracy: {0:.2%}\".format(result[\"accuracy\"]))\n",
    "    sys.stdout.flush()\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from model5/model.ckpt-7035\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./trained_models/export/temp-b'1546878219'/saved_model.pbtxt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./trained_models/export/1546878219'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_serving_input_receiver_fn():\n",
    "    inputs = {'image': tf.placeholder(shape=[28,28,1], dtype=tf.float32, name='image')}\n",
    "    return tf.estimator.export.build_raw_serving_input_receiver_fn(inputs)\n",
    "\n",
    "export_dir = os.path.join('./trained_models/', 'export')\n",
    "\n",
    "if tf.gfile.Exists(export_dir):\n",
    "        tf.gfile.DeleteRecursively(export_dir)\n",
    "\n",
    "model.export_savedmodel(\n",
    "    export_dir_base=export_dir,\n",
    "    serving_input_receiver_fn=make_serving_input_receiver_fn(),\n",
    "    as_text=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained_models/export/1546878219/variables/variables\n"
     ]
    }
   ],
   "source": [
    "export_dir = os.path.join('./trained_models/', 'export')\n",
    "saved_model_dir = os.path.join(export_dir, os.listdir(export_dir)[-1]) \n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "  export_dir = saved_model_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probabilities': array([[1.6141685e-02, 1.9623837e-06, 9.7868425e-01, 6.2382333e-06,\n",
      "        2.4321977e-07, 4.9259742e-03, 2.0042721e-04, 1.9268622e-05,\n",
      "        1.8677925e-05, 1.3576388e-06]], dtype=float32), 'classes': array([2])}\n",
      "train_data.shape: (?, ?, 1)\n",
      "train_data.shape: (28, 28, 1)\n",
      "P for  0 is 1.61\n",
      "P for  1 is 0.00\n",
      "P for  2 is 97.87\n",
      "P for  3 is 0.00\n",
      "P for  4 is 0.00\n",
      "P for  5 is 0.49\n",
      "P for  6 is 0.02\n",
      "P for  7 is 0.00\n",
      "P for  8 is 0.00\n",
      "P for  9 is 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "#data_dict = _read_pickle_from_file('cifar-10/cifar-10-batches-py/test_batch')\n",
    "\n",
    "pngFname = target + \"/PNGs/\" + \"train_%d.png\" % (1984)\n",
    "pngFile=open(pngFname,'rb')\n",
    "png_string = pngFile.read();\n",
    "pngFile.close()\n",
    "\n",
    "#sample = tf.cast(tf.image.decode_png(png_string, channels=1), tf.int8)\n",
    "sample = tf.cast(tf.image.decode_png(png_string, channels=1), tf.float32)\n",
    "\n",
    "a = np.ones(shape=(28,28,1),dtype=np.float32)    \n",
    "\n",
    "img = tf.reshape(sample, [28, 28, 1])\n",
    "\n",
    "with sess.as_default():\n",
    "    a = img.eval()\n",
    "\n",
    "output = predictor_fn({'image': a})\n",
    "print(output)\n",
    "\n",
    "print (\"train_data.shape: \" + str(sample.get_shape()))\n",
    "print (\"train_data.shape: \" + str(img.get_shape()))\n",
    "\n",
    "for x in range(10):\n",
    "    print(\"P for \", x, \"is {:.2f}\".format(output['probabilities'][0][x]*100));\n",
    "\n",
    "\n",
    "#img = sample.reshape([28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
